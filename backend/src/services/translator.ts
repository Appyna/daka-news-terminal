import OpenAI from 'openai';
import dotenv from 'dotenv';
import { getCachedTranslation, saveCachedTranslation } from './database';

dotenv.config();

const OPENAI_API_KEY = process.env.OPENAI_API_KEY;

if (!OPENAI_API_KEY) {
  throw new Error('‚ùå OPENAI_API_KEY manquante dans .env');
}

const openai = new OpenAI({ apiKey: OPENAI_API_KEY });

/**
 * Traduire un texte (avec cache automatique)
 */
export async function translateText(
  text: string,
  fromLang: string = 'he',
  toLang: string = 'fr'
): Promise<string> {
  // V√©rifier le cache d'abord (√©conomise les appels OpenAI)
  const cached = await getCachedTranslation(text, fromLang, toLang);
  if (cached) {
    // console.log(`‚úÖ Cache hit pour: "${text.substring(0, 30)}..."`);
    return cached;
  }

  try {
    // ‚úÖ Prompts sp√©cialis√©s selon la langue source
    let systemPrompt = '';
    
    if (fromLang === 'he') {
      // üáÆüá± PROMPT POUR L'H√âBREU (Sources Isra√´l)
      systemPrompt = `Tu es un traducteur sp√©cialis√© dans l'actualit√© isra√©lienne.
Traduis ce titre de presse de l'h√©breu vers le fran√ßais.
- Style: journalistique, accrocheur, concis
- Ton: neutre et factuel
- Contexte: actualit√©s g√©opolitiques (Isra√´l, Moyen-Orient)
- Format: titre court et percutant (max 15 mots)
R√©ponds UNIQUEMENT avec la traduction, sans explication.`;
    } else if (fromLang === 'en') {
      // üåç PROMPT POUR L'ANGLAIS (Sources Monde)
      systemPrompt = `Tu es un traducteur sp√©cialis√© dans l'actualit√© internationale.
Traduis ce titre de presse de l'anglais vers le fran√ßais.
- Style: journalistique fran√ßais (type Le Monde, AFP)
- Ton: neutre, factuel, professionnel
- Format: titre fran√ßais naturel (max 15 mots)
- Conserve l'impact et l'urgence du titre original
R√©ponds UNIQUEMENT avec la traduction, sans explication.`;
    } else {
      // üîÑ FALLBACK (autres langues)
      systemPrompt = `Tu es un traducteur professionnel. Traduis le texte suivant de ${fromLang} vers ${toLang}. R√©ponds UNIQUEMENT avec la traduction, sans aucune explication.`;
    }

    // ‚úÖ Appel OpenAI seulement si pas en cache
    const response = await openai.chat.completions.create({
      model: 'gpt-4o-mini',
      messages: [
        {
          role: 'system',
          content: systemPrompt
        },
        {
          role: 'user',
          content: text
        }
      ],
      temperature: 0.3,
      max_tokens: 500
    });

    const translation = response.choices[0]?.message?.content?.trim() || text;

    // Sauvegarder dans le cache pour la prochaine fois
    await saveCachedTranslation(text, translation, fromLang, toLang);

    return translation;
  } catch (error: any) {
    // G√©rer les erreurs de rate limit sp√©cifiquement
    if (error.message?.includes('429') || error.message?.includes('Rate limit')) {
      console.error('‚ö†Ô∏è Rate limit OpenAI atteint - utilisation de l\'original');
    } else {
      console.error('‚ùå Erreur traduction OpenAI:', error.message);
    }
    return text; // Fallback: retourner le texte original
  }
}

/**
 * Traduire un batch de textes (avec cache)
 */
export async function translateBatch(
  texts: string[],
  fromLang: string = 'he',
  toLang: string = 'fr'
): Promise<string[]> {
  const translations: string[] = [];

  for (const text of texts) {
    const translation = await translateText(text, fromLang, toLang);
    translations.push(translation);
  }

  return translations;
}

console.log('‚úÖ Service de traduction OpenAI configur√©');
